{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY1NLmEwrR6s",
        "outputId": "ebb4b394-1c45-4e73-aefb-57e1c8ef4b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl (867 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m867.6/867.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.5-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.36 (from langchain)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.48 (from langchain)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.54-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.48->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.5 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.17 langchain-community-0.0.36 langchain-core-0.1.50 langchain-text-splitters-0.0.1 langsmith-0.1.54 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "  !pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCCOZahurCEj",
        "outputId": "35459cf5-9ed1-44fd-c312-a127e8c5c948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HNNpc8pr4Nx",
        "outputId": "af2245f5-4626-4b2d-a452-18de64f926cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.50)\n",
            "Collecting openai<2.0.0,>=1.24.0 (from langchain_openai)\n",
            "  Downloading openai-1.25.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.1.54)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Installing collected packages: h11, tiktoken, httpcore, httpx, openai, langchain_openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain_openai-0.1.6 openai-1.25.1 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXNwP3ClsDrT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eROV4_HThZQS",
        "outputId": "67749865-7bc2-43ad-829f-19409b225c38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC3cPtzgqHZY",
        "outputId": "d7c4cbf6-a0bc-40b1-b63a-c6bdf2e02afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    Text: \n",
            "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\"Norman\" comes from \"Norseman\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
            "\n",
            "    You are an expert MCQ maker. Given the above text, it is your job to \n",
            "    create a quiz of 5 multiple choice questions for English students in Simple tone. \n",
            "    Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
            "    Make sure to format your response like RESPONSE_JSON below and use it as a guide.\n",
            "    Ensure to make 5 MCQs\n",
            "    ### RESPONSE_JSON\n",
            "    \"{\\\"1\\\": {\\\"question\\\": \\\"What is the main contribution of the paper?\\\", \\\"options\\\": {\\\"a\\\": \\\"Question answering methods\\\", \\\"b\\\": \\\"Neural network training\\\", \\\"c\\\": \\\"Data collection from CQA websites\\\", \\\"d\\\": \\\"Question generation approaches\\\"}, \\\"correct_answer\\\": \\\"Data collection from CQA websites\\\"}, \\\"2\\\": {\\\"question\\\": \\\"How many question generation approaches are proposed in the paper?\\\", \\\"options\\\": {\\\"a\\\": \\\"One\\\", \\\"b\\\": \\\"Two\\\", \\\"c\\\": \\\"Three\\\", \\\"d\\\": \\\"Four\\\"}, \\\"correct_answer\\\": \\\"Two\\\"}, \\\"3\\\": {\\\"question\\\": \\\"What is the main advantage of using CQA websites for training data collection?\\\", \\\"options\\\": {\\\"a\\\": \\\"Low quality data\\\", \\\"b\\\": \\\"High cost\\\", \\\"c\\\": \\\"Real user-generated content\\\", \\\"d\\\": \\\"Limited information\\\"}, \\\"correct_answer\\\": \\\"Real user-generated content\\\"}, \\\"4\\\": {\\\"question\\\": \\\"How is question topic selection performed in the generation-based method?\\\", \\\"options\\\": {\\\"a\\\": \\\"Based on pre-defined rules\\\", \\\"b\\\": \\\"Using entity recognition\\\", \\\"c\\\": \\\"Attention mechanism\\\", \\\"d\\\": \\\"Random selection\\\"}, \\\"correct_answer\\\": \\\"Attention mechanism\\\"}, \\\"5\\\": {\\\"question\\\": \\\"What does the improvement on MS MARCO dataset indicate?\\\", \\\"options\\\": {\\\"a\\\": \\\"Better question generation performance\\\", \\\"b\\\": \\\"Quality of questions from Bing search log\\\", \\\"c\\\": \\\"Crowdsourced data\\\", \\\"d\\\": \\\"No impact on QA systems\\\"}, \\\"correct_answer\\\": \\\"Quality of questions from Bing search log\\\"}}\"\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "    You are an expert English grammarian and writer. Given a Multiple Choice Quiz for English students.\n",
            "    You need to evaluate the complexity of the questions and give a complete analysis of the quiz. Only use at max 50 words for complexity if the quiz is not at per with the cognitive and analytical abilities of the students,\n",
            "    update the quiz questions which needs to be change the tone such that it perfectly fits the students ability.\n",
            "    Quiz_MCQs:\n",
            "    ### RESPONSE_JSON\n",
            "{\n",
            "    \"1\": {\n",
            "        \"question\": \"Where did the Normans give their name to in the 10th and 11th centuries?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"England\",\n",
            "            \"b\": \"Scotland\",\n",
            "            \"c\": \"Ireland\",\n",
            "            \"d\": \"Normandy\"\n",
            "        },\n",
            "        \"correct_answer\": \"Normandy\"\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"question\": \"From which countries were the Normans descended?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"Spain and Portugal\",\n",
            "            \"b\": \"Denmark, Iceland, and Norway\",\n",
            "            \"c\": \"Italy and Greece\",\n",
            "            \"d\": \"Germany and Austria\"\n",
            "        },\n",
            "        \"correct_answer\": \"Denmark, Iceland, and Norway\"\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"question\": \"Who did the Normans agree to swear fealty to?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"King Charles II of West Francia\",\n",
            "            \"b\": \"King Charles III of West Francia\",\n",
            "            \"c\": \"King Charles IV of West Francia\",\n",
            "            \"d\": \"King Charles V of West Francia\"\n",
            "        },\n",
            "        \"correct_answer\": \"King Charles III of West Francia\"\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"question\": \"In which century did the distinct cultural and ethnic identity of the Normans emerge?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"9th century\",\n",
            "            \"b\": \"10th century\",\n",
            "            \"c\": \"11th century\",\n",
            "            \"d\": \"12th century\"\n",
            "        },\n",
            "        \"correct_answer\": \"10th century\"\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"question\": \"With whom did the Normans gradually merge through generations of assimilation and mixing?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"Vikings\",\n",
            "            \"b\": \"Native Frankish and Roman-Gaulish populations\",\n",
            "            \"c\": \"Anglo-Saxons\",\n",
            "            \"d\": \"Celts\"\n",
            "        },\n",
            "        \"correct_answer\": \"Native Frankish and Roman-Gaulish populations\"\n",
            "    }\n",
            "}\n",
            "\n",
            "    Check from an expert English Writer of the above quiz.\n",
            "    \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Quiz response: ### RESPONSE_JSON\n",
            "{\n",
            "    \"1\": {\n",
            "        \"question\": \"Where did the Normans give their name to in the 10th and 11th centuries?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"England\",\n",
            "            \"b\": \"Scotland\",\n",
            "            \"c\": \"Ireland\",\n",
            "            \"d\": \"Normandy\"\n",
            "        },\n",
            "        \"correct_answer\": \"Normandy\"\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"question\": \"From which countries were the Normans descended?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"Spain and Portugal\",\n",
            "            \"b\": \"Denmark, Iceland, and Norway\",\n",
            "            \"c\": \"Italy and Greece\",\n",
            "            \"d\": \"Germany and Austria\"\n",
            "        },\n",
            "        \"correct_answer\": \"Denmark, Iceland, and Norway\"\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"question\": \"Who did the Normans agree to swear fealty to?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"King Charles II of West Francia\",\n",
            "            \"b\": \"King Charles III of West Francia\",\n",
            "            \"c\": \"King Charles IV of West Francia\",\n",
            "            \"d\": \"King Charles V of West Francia\"\n",
            "        },\n",
            "        \"correct_answer\": \"King Charles III of West Francia\"\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"question\": \"In which century did the distinct cultural and ethnic identity of the Normans emerge?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"9th century\",\n",
            "            \"b\": \"10th century\",\n",
            "            \"c\": \"11th century\",\n",
            "            \"d\": \"12th century\"\n",
            "        },\n",
            "        \"correct_answer\": \"10th century\"\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"question\": \"With whom did the Normans gradually merge through generations of assimilation and mixing?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"Vikings\",\n",
            "            \"b\": \"Native Frankish and Roman-Gaulish populations\",\n",
            "            \"c\": \"Anglo-Saxons\",\n",
            "            \"d\": \"Celts\"\n",
            "        },\n",
            "        \"correct_answer\": \"Native Frankish and Roman-Gaulish populations\"\n",
            "    }\n",
            "}\n",
            "Quiz generated successfully!\n",
            "Output from GPT-3.5 Turbo model:\n",
            "### RESPONSE_JSON\n",
            "{\n",
            "    \"1\": {\n",
            "        \"question\": \"Where did the Normans give their name to in the 10th and 11th centuries?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"England\",\n",
            "            \"b\": \"Scotland\",\n",
            "            \"c\": \"Ireland\",\n",
            "            \"d\": \"Normandy\"\n",
            "        },\n",
            "        \"correct_answer\": \"Normandy\"\n",
            "    },\n",
            "    \"2\": {\n",
            "        \"question\": \"From which countries were the Normans descended?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"Spain and Portugal\",\n",
            "            \"b\": \"Denmark, Iceland, and Norway\",\n",
            "            \"c\": \"Italy and Greece\",\n",
            "            \"d\": \"Germany and Austria\"\n",
            "        },\n",
            "        \"correct_answer\": \"Denmark, Iceland, and Norway\"\n",
            "    },\n",
            "    \"3\": {\n",
            "        \"question\": \"Who did the Normans agree to swear fealty to?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"King Charles II of West Francia\",\n",
            "            \"b\": \"King Charles III of West Francia\",\n",
            "            \"c\": \"King Charles IV of West Francia\",\n",
            "            \"d\": \"King Charles V of West Francia\"\n",
            "        },\n",
            "        \"correct_answer\": \"King Charles III of West Francia\"\n",
            "    },\n",
            "    \"4\": {\n",
            "        \"question\": \"In which century did the distinct cultural and ethnic identity of the Normans emerge?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"9th century\",\n",
            "            \"b\": \"10th century\",\n",
            "            \"c\": \"11th century\",\n",
            "            \"d\": \"12th century\"\n",
            "        },\n",
            "        \"correct_answer\": \"10th century\"\n",
            "    },\n",
            "    \"5\": {\n",
            "        \"question\": \"With whom did the Normans gradually merge through generations of assimilation and mixing?\",\n",
            "        \"options\": {\n",
            "            \"a\": \"Vikings\",\n",
            "            \"b\": \"Native Frankish and Roman-Gaulish populations\",\n",
            "            \"c\": \"Anglo-Saxons\",\n",
            "            \"d\": \"Celts\"\n",
            "        },\n",
            "        \"correct_answer\": \"Native Frankish and Roman-Gaulish populations\"\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import traceback\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "\n",
        "# Get the OpenAI API key\n",
        "OPENAI_API_KEY = \"YOUR_OPEN_API_KEY\"\n",
        "\n",
        "# Example text\n",
        "example_text = \"\"\"\n",
        "The Normans (Norman: Nourmands; French: Normands; Latin: Normanni) were the people who in the 10th and 11th centuries gave their name to Normandy, a region in France. They were descended from Norse (\\\"Norman\\\" comes from \\\"Norseman\\\") raiders and pirates from Denmark, Iceland and Norway who, under their leader Rollo, agreed to swear fealty to King Charles III of West Francia. Through generations of assimilation and mixing with the native Frankish and Roman-Gaulish populations, their descendants would gradually merge with the Carolingian-based cultures of West Francia. The distinct cultural and ethnic identity of the Normans emerged initially in the first half of the 10th century, and it continued to evolve over the succeeding centuries.\n",
        "\"\"\"\n",
        "\n",
        "# Function to generate quiz and evaluate\n",
        "def generate_and_evaluate_quiz(text, number, subject, tone):\n",
        "    RESPONSE_JSON = '{\"1\": {\"question\": \"What is the main contribution of the paper?\", \"options\": {\"a\": \"Question answering methods\", \"b\": \"Neural network training\", \"c\": \"Data collection from CQA websites\", \"d\": \"Question generation approaches\"}, \"correct_answer\": \"Data collection from CQA websites\"}, \"2\": {\"question\": \"How many question generation approaches are proposed in the paper?\", \"options\": {\"a\": \"One\", \"b\": \"Two\", \"c\": \"Three\", \"d\": \"Four\"}, \"correct_answer\": \"Two\"}, \"3\": {\"question\": \"What is the main advantage of using CQA websites for training data collection?\", \"options\": {\"a\": \"Low quality data\", \"b\": \"High cost\", \"c\": \"Real user-generated content\", \"d\": \"Limited information\"}, \"correct_answer\": \"Real user-generated content\"}, \"4\": {\"question\": \"How is question topic selection performed in the generation-based method?\", \"options\": {\"a\": \"Based on pre-defined rules\", \"b\": \"Using entity recognition\", \"c\": \"Attention mechanism\", \"d\": \"Random selection\"}, \"correct_answer\": \"Attention mechanism\"}, \"5\": {\"question\": \"What does the improvement on MS MARCO dataset indicate?\", \"options\": {\"a\": \"Better question generation performance\", \"b\": \"Quality of questions from Bing search log\", \"c\": \"Crowdsourced data\", \"d\": \"No impact on QA systems\"}, \"correct_answer\": \"Quality of questions from Bing search log\"}}'\n",
        "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\", temperature=0.5)\n",
        "\n",
        "    PROMPT_TEMPLATE = \"\"\"\n",
        "    Text: {text}\n",
        "    You are an expert MCQ maker. Given the above text, it is your job to\n",
        "    create a quiz of {number} multiple choice questions for {subject} students in {tone} tone.\n",
        "    Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
        "    Make sure to format your response like RESPONSE_JSON below and use it as a guide.\n",
        "    Ensure to make {number} MCQs\n",
        "    ### RESPONSE_JSON\n",
        "    {response_json}\n",
        "    \"\"\"\n",
        "\n",
        "    quiz_generation_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
        "    template=PROMPT_TEMPLATE\n",
        "    )\n",
        "    quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)\n",
        "\n",
        "    EVALUATION_PROMPT_TEMPLATE = \"\"\"\n",
        "    You are an expert English grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\n",
        "    You need to evaluate the complexity of the questions and give a complete analysis of the quiz. Only use at max 50 words for complexity if the quiz is not at per with the cognitive and analytical abilities of the students,\n",
        "    update the quiz questions which needs to be change the tone such that it perfectly fits the students ability.\n",
        "    Quiz_MCQs:\n",
        "    {quiz}\n",
        "\n",
        "    Check from an expert English Writer of the above quiz.\n",
        "    \"\"\"\n",
        "\n",
        "    quiz_evaluation_prompt = PromptTemplate(\n",
        "        input_variables=[\"subject\", \"quiz\"],\n",
        "        template=EVALUATION_PROMPT_TEMPLATE\n",
        "    )\n",
        "\n",
        "    # Connect the both chain to get the actual output using Sequential Chain\n",
        "    quiz_evaluation_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)\n",
        "\n",
        "    generate_evaluate_chains = SequentialChain(chains=[quiz_chain, quiz_evaluation_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"], output_variables=[\"quiz\", \"review\"], verbose=True)\n",
        "\n",
        "    response = generate_evaluate_chains(\n",
        "        {\n",
        "        \"text\": text,\n",
        "        \"number\": number,\n",
        "        \"subject\": subject,\n",
        "        \"tone\": tone,\n",
        "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
        "        }\n",
        "    )\n",
        "    quiz_response = response['quiz']\n",
        "    print(\"Quiz response:\", quiz_response)\n",
        "    # quiz_dict = json.loads(quiz_response)\n",
        "\n",
        "    return quiz_response\n",
        "\n",
        "# Generate and evaluate quiz\n",
        "try:\n",
        "    quiz_output = generate_and_evaluate_quiz(example_text, number=5, subject=\"English\", tone=\"Simple\")\n",
        "    print(\"Quiz generated successfully!\")\n",
        "    print(\"Output from GPT-3.5 Turbo model:\")\n",
        "    print(quiz_output)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    print(traceback.format_exc())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7V516TjC29d",
        "outputId": "9a82fb3d-141d-4b34-83c9-9044b6a75905"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Rouge) (1.16.0)\n",
            "Installing collected packages: Rouge\n",
            "Successfully installed Rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install Rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CikZTTK6xTp2",
        "outputId": "a2b45a14-355b-4406-b178-b61ab8888f75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=06d9b9538dca8e2556b608af8a7075c70f6b36b9fb6c2c3cc96c909bdacc2773\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install rouge_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCZqDsCqxMgP",
        "outputId": "c647d6c0-8e12-44ca-e2be-3d12f96ffa29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT 3.5 Turbo:\n",
            " {'rouge1': 0.23441295546558702, 'rouge2': 0.1393939393939394, 'rougeL': 0.23553423693011794, 'rougeLsum': 0.23553423693011794}\n"
          ]
        }
      ],
      "source": [
        "import evaluate\n",
        "from rouge import Rouge\n",
        "\n",
        "reference_questions = [\n",
        "    \"In what country is Normandy located?\",\n",
        "    \"When were the Normans in Normandy?\",\n",
        "    \"From which countries did the Norse originate?\",\n",
        "    \"Who was the Norse leader?\",\n",
        "    \"What century did the Normans first gain their separate identity?\"\n",
        "]\n",
        "\n",
        "generated_questions = [\n",
        "    \"Where did the Normans give their name to in the 10th and 11th centuries?\",\n",
        "    \"From which countries were the Normans descended?\",\n",
        "    \"Who did the Normans agree to swear fealty to?\",\n",
        "    \"In which century did the distinct cultural and ethnic identity of the Normans emerge?\",\n",
        "    \"With whom did the Normans gradually merge through generations of assimilation and mixing?\"\n",
        "]\n",
        "\n",
        "# Initialize Rouge\n",
        "rouge = evaluate.load('rouge')\n",
        "\n",
        "original_model_results = rouge.compute(\n",
        "    predictions=generated_questions,\n",
        "    references=reference_questions,\n",
        "    use_aggregator=True,\n",
        "    use_stemmer=True,\n",
        ")\n",
        "\n",
        "print(\"GPT 3.5 Turbo:\\n\", original_model_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXZg53Oq62rj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
